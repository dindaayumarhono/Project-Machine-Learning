# -*- coding: utf-8 -*-
"""MODEL. ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lHn-2lbfBRGFA0F-MRc5rBclhFS0vwOH

#library
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import os
from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (
    accuracy_score, make_scorer, precision_score, recall_score,
    f1_score, roc_auc_score, classification_report, confusion_matrix, RocCurveDisplay
)

"""#load data"""

from google.colab import drive
drive.mount('/content/drive')

#LOAD DATA
data = pd.read_csv('/content/drive/MyDrive/machine learning/healthcare-dataset-stroke-data.csv', sep=';')
data

"""#preprocessing"""

#TARGET DATA
target = "stroke"
X = data.drop(columns=[target])
y = data[target]

#PEMBAGIAN DATA UJI DAN LATIH
X_train, X_temp, y_train, y_temp = train_test_split(
    X, y, test_size=0.3, stratify=y, random_state=42
)

X_val, X_test, y_val, y_test = train_test_split(
    X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42
)

print("Train :", X_train.shape)
print("Val   :", X_val.shape)
print("Test  :", X_test.shape)

#IDENTIFIKASI FITUR
categorical_cols = X.select_dtypes(include=["object"]).columns.tolist()
numeric_cols = X.select_dtypes(include=["int64", "float64"]).columns.tolist()
numeric_cols = [col for col in numeric_cols if col not in categorical_cols]

print("Categorical:", categorical_cols)
print("Numeric:", numeric_cols)

#PREPROCESSING PIPELINE
numeric_pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
])

categorical_pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])

preprocess = ColumnTransformer([
    ('num', numeric_pipeline, numeric_cols),
    ('cat', categorical_pipeline, categorical_cols)
])

#MODEL PIPELINE
pipeline = Pipeline([
    ('preprocess', preprocess),
    ('model', LogisticRegression(max_iter=300, class_weight='balanced', random_state=42))
])

#FIT PREPROCESSING
preprocess.fit(X_train)

#HASIL DATAFRAME PREPROCESSED
def get_preprocessed_df(preprocess_pipeline, X, numeric_cols, categorical_cols):

    # Transform
    X_array = preprocess_pipeline.transform(X)

    # Kolom numerik
    num_cols = numeric_cols

    # Kolom kategorikal hasil OHE
    cat_cols = preprocess_pipeline.named_transformers_['cat']['onehot'] \
        .get_feature_names_out(categorical_cols)

    # Gabungkan nama kolom
    all_cols = np.concatenate([num_cols, cat_cols])

    # Buat DataFrame dengan index sesuai X asli
    return pd.DataFrame(X_array, columns=all_cols, index=X.index)

#TRANSFORM
X_train_pre = get_preprocessed_df(preprocess, X_train, numeric_cols, categorical_cols)
X_val_pre   = get_preprocessed_df(preprocess, X_val, numeric_cols, categorical_cols)
X_test_pre  = get_preprocessed_df(preprocess, X_test, numeric_cols, categorical_cols)

#SIMPAN KE DRIVE
csv_path = "/content/drive/MyDrive/machine learning/stroke_preprocessed.csv"
X_all_pre.to_csv(csv_path, index=True)

print(f"Dataset berhasil diekspor ke {csv_path}")

"""#cross validation"""

#CROSS VALIDATION
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# Scoring fokus pada kelas minor (stroke=1)
scoring = {
    'accuracy': 'accuracy',
    'precision_min': make_scorer(precision_score, pos_label=1),
    'recall_min': make_scorer(recall_score, pos_label=1),
    'f1_min': make_scorer(f1_score, pos_label=1),
    'roc_auc': 'roc_auc'
}

cv_result = cross_validate(
    pipeline,
    X_train,
    y_train,
    cv=cv,
    scoring=scoring,
    return_train_score=False
)

#HASIL CV
print("\n=== PER-FOLD METRIC (TRAIN SET CV) ===")
for i in range(5):
    print(
        f"Fold {i+1}: "
        f"Acc={cv_result['test_accuracy'][i]:.4f}, "
        f"Prec={cv_result['test_precision_min'][i]:.4f}, "
        f"Recall={cv_result['test_recall_min'][i]:.4f}, "
        f"F1={cv_result['test_f1_min'][i]:.4f}, "
        f"AUC={cv_result['test_roc_auc'][i]:.4f}"
    )

#MEAN & RESULTS
print("\n=== CV Mean ± Std ===")
for metric in scoring.keys():
    mean = np.mean(cv_result[f'test_{metric}'])
    std = np.std(cv_result[f'test_{metric}'])
    print(f"{metric:10s}: {mean:.4f} ± {std:.4f}")

"""#train model"""

final_model = RandomForestClassifier(
    n_estimators=300,
    class_weight="balanced",
    random_state=42
)

final_model.fit(X_train_pre, y_train)
print("Model final berhasil dilatih!")

"""#evaluasi validation set"""

y_val_pred = final_model.predict(X_val_pre)
y_val_proba = final_model.predict_proba(X_val_pre)[:, 1]

print("\n=== VALIDATION PERFORMANCE ===")
print("Accuracy :", accuracy_score(y_val, y_val_pred))
print("Precision:", precision_score(y_val, y_val_pred))
print("Recall   :", recall_score(y_val, y_val_pred))
print("F1-score :", f1_score(y_val, y_val_pred))
print("ROC-AUC  :", roc_auc_score(y_val, y_val_proba))

"""#evaluasi test set"""

y_test_pred = final_model.predict(X_test_pre)
y_test_proba = final_model.predict_proba(X_test_pre)[:, 1]

print("\n=== TEST SET PERFORMANCE (FINAL) ===")
print("Accuracy :", accuracy_score(y_test, y_test_pred))
print("Precision:", precision_score(y_test, y_test_pred))
print("Recall   :", recall_score(y_test, y_test_pred))
print("F1-score :", f1_score(y_test, y_test_pred))
print("ROC-AUC  :", roc_auc_score(y_test, y_test_proba))